{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load data for eye position and a CEBRA-Time model ##\n",
    "\n",
    "# for a single fish\n",
    "filename = FILENAME\n",
    "filename_trunc = filename.split('/')[-1][:-3] # fish and date only\n",
    "data_folder = 'data/'\n",
    "\n",
    "# choose where in dataset to sample\n",
    "start, stop = 0, 0+TIMESTEPS\n",
    "\n",
    "\n",
    "# extract eye position and neural data\n",
    "# do not attempt to load the entire file \n",
    "print(\"Accessing data...\")\n",
    "with h5py.File(filename, 'r') as f:\n",
    "\n",
    "    # eye position\n",
    "    eye_pos_l = f['visuomotor']['eye_pos']['Left']\n",
    "    eye_pos_r = f['visuomotor']['eye_pos']['Right']\n",
    "    print(f\"Full eye position dataset shape is: {eye_pos_l.shape}\")\n",
    "\n",
    "    # neural \n",
    "    neural = f['rois']['dfof']\n",
    "    print(f\"Full neural dataset shape is: {neural.shape}\")\n",
    "\n",
    "    # select first TIMESTEPS timesteps and random ROIS rois\n",
    "    # neural\n",
    "    neural_indexes = np.sort(\n",
    "                        np.random.choice(\n",
    "                                    np.arange(neural.shape[1]), size=ROIS, replace=False\n",
    "                                    )\n",
    "                        )\n",
    "    neural = np.array(neural[start:stop, neural_indexes])\n",
    "\n",
    "    # eye position\n",
    "    eye_pos_l = np.array(eye_pos_l[start:stop])\n",
    "    eye_pos_r = np.array(eye_pos_r[start:stop])\n",
    "\n",
    "    print(f\"Truncated dataset shapes are:\\n \\\n",
    "            eye_pos_l: {eye_pos_l.shape}\\n \\\n",
    "            eye_pos_r: {eye_pos_r.shape}\\n \\\n",
    "            neural: {neural.shape}\")\n",
    "\n",
    "    assert(neural.shape == (TIMESTEPS, ROIS))\n",
    "\n",
    "\n",
    "    # save datasets\n",
    "    filename_eye_pos = f'{filename[-12:-3]}_eye_pos.npz'\n",
    "    filename_dfof = f'{filename[-12:-3]}_dfof.npz'\n",
    "    np.savez(f'{data_folder} + {filename_eye_pos}', eye_pos_l=eye_pos_l, eye_pos_r=eye_pos_r)\n",
    "    np.savez(f'{data_folder} + {filename_dfof}', neural=neural)\n",
    "\n",
    "print(\"Data accessed.\")\n",
    "\n",
    "eye_pos_l = cebra.load_data(f'{data_folder}{filename_eye_pos}', key=\"eye_pos_l\")\n",
    "print(f\"{filename_eye_pos}_left loaded.\")\n",
    "eye_pos_r = cebra.load_data(filename_eye_pos, key=\"eye_pos_r\")\n",
    "print(f\"{filename_eye_pos}_right loaded.\")\n",
    "neural = cebra.load_data(f'{data_folder}{filename_eye_pos}', key=\"neural\")\n",
    "print(f\"{filename_dfof} loaded.\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## truncate nueral data to be a random selection of ROIs and a consecutive sequence of timesteps, with predefined shape ##\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "# truncate neural\n",
    "# select first TIMESTEPS timesteps and random ROIS rois\n",
    "neural_indexes = np.sort(\n",
    "                    np.random.choice(\n",
    "                                np.arange(neural.shape[1]), size=ROIS, replace=False\n",
    "                                )\n",
    "                    )\n",
    "neural = np.array(neural[start:stop, neural_indexes])\n",
    "print(f'Truncated neural dataset shape is: {neural.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##  singular (non-loop) implementation of creating binary masks for stimulus 'on' frames ##\n",
    "\n",
    "import h5py\n",
    "\n",
    "filepath = '/media/storage/DATA/lfads_export/f1_221027.h5'\n",
    "stim_types = {'left_spot':0, 'right_spot':1,  \\\n",
    "              'open_loop_grating':2, 'closed_loop_grating':3}\n",
    "neural = np.zeros((100000,1))\n",
    "\n",
    "with h5py.File(filepath, 'r') as f:\n",
    "\n",
    "    # get stimulus presentations\n",
    "    stimuli = f['visuomotor']['presentations']\n",
    "    stim_type = stimuli['stim_type'].astype(int)\n",
    "    stim_onset_fr = stimuli['onset_frame'].astype(int)\n",
    "    stim_end_fr = stimuli['offset_frame'].astype(int)\n",
    "\n",
    "\n",
    "    # find the presentation indexes with left or right spots\n",
    "    stim_pres_idx_l = np.where(np.isin(stim_type, 1))[0]    # left spots\n",
    "    stim_pres_idx_r = np.where(np.isin(stim_type, 2))[0]    # right spots\n",
    "\n",
    "    # index stim onset frames with the presentation indexes\n",
    "    stim_onset_fr = stimuli['onset_frame'].astype(int)\n",
    "    stim_pres_fr_l = stim_onset_fr[stim_pres_idx_l]\n",
    "    stim_pres_fr_r = stim_onset_fr[stim_pres_idx_r]\n",
    "\n",
    "    # index stim end frames with the presentation indexes\n",
    "    stim_end_fr = stimuli['offset_frame'].astype(int)\n",
    "    stim_end_fr_l = stim_end_fr[stim_pres_idx_l]\n",
    "    stim_end_fr_r = stim_end_fr[stim_pres_idx_r]\n",
    "\n",
    "    # create masks of stim onset/stim end\n",
    "    # left spot\n",
    "    stim_on_l = np.zeros(neural.shape[0]).astype(int)\n",
    "    stim_on_l[[stim_pres_fr_l, stim_end_fr_l]] = 1\n",
    "    np.bitwise_xor.accumulate(stim_on_l) | stim_on_l\n",
    "    # right spot\n",
    "    stim_on_r = np.zeros(neural.shape[0]).astype(int)\n",
    "    stim_on_r[[stim_pres_fr_r, stim_end_fr_r]] = 1\n",
    "    np.bitwise_xor.accumulate(stim_on_r) | stim_on_r\n",
    "\n",
    "    # find duration (in frames) of each presentation\n",
    "    # (neural recording is at 5Hz)\n",
    "    stim_dur_l = stim_end_fr_l - stim_pres_fr_l\n",
    "    stim_dur_r = stim_end_fr_r - stim_pres_fr_r"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
