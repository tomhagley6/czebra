{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test SPIM data CEBRA model\n",
    "\n",
    "- Use CEBRA label contrastive learning on neural data from one fish\n",
    "    - design model\n",
    "    - convert SPIM data to usable format \n",
    "    - load data\n",
    "    - fit with label\n",
    "    - plot embeddings\n",
    "    - try to predict stimulus presence\n",
    "    - try to decode stimulus type (left/right spots)\n",
    "        - create a discrete variable that labels the post-stimulus frames for right and left spots\n",
    "        - This should inform the decoder to separate embedding states (which should vary between left and right spots)<br/><br/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cebra\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import h5py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # define globals\n",
    "\n",
    "# list of all data files\n",
    "dat_files = ['/media/storage/DATA/lfads_export/f1_221027.h5',\n",
    "             '/media/storage/DATA/lfads_export/f1_221103.h5',\n",
    "             '/media/storage/DATA/lfads_export/f2_221103.h5',\n",
    "             '/media/storage/DATA/lfads_export/f3_221103.h5']\n",
    "\n",
    "global FILEPATH\n",
    "global TIMESTEPS\n",
    "global ROIS\n",
    "global ITERS\n",
    "global LOAD\n",
    "global STIM_TYPES\n",
    "global STIMS\n",
    "global STIM_MASKS\n",
    "\n",
    "FILEPATH = dat_files[0]\n",
    "TIMESTEPS = 15000\n",
    "ROIS = 10000\n",
    "ITERS = 15000\n",
    "LOAD = False\n",
    "STIM_TYPES = {'left_spot':0, 'right_spot':1,  \\\n",
    "              'open_loop_grating':2, 'closed_loop_grating':3}\n",
    "STIMS = ['left_spot', 'right_spot']\n",
    "STIM_MASKS = [['left_spot', 'right_spot']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CEBRA(conditional='time', learning_rate=0.0001, max_iterations=15000,\n",
      "      model_architecture='offset10-model', output_dimension=3,\n",
      "      temperature_mode='auto', time_offsets=10, verbose=True)\n"
     ]
    }
   ],
   "source": [
    "# # define model\n",
    "\n",
    "cebra_time_model = cebra.CEBRA(\n",
    "    model_architecture='offset10-model',\n",
    "    device='cuda_if_available',\n",
    "    conditional='time',\n",
    "    temperature_mode='auto',\n",
    "    min_temperature=0.1,\n",
    "    time_offsets=10,\n",
    "    max_iterations=ITERS,\n",
    "    max_adapt_iterations=500,\n",
    "    batch_size=None,\n",
    "    learning_rate=1e-4,\n",
    "    output_dimension=3,\n",
    "    verbose=True,\n",
    "    num_hidden_units=32,\n",
    "    hybrid=False\n",
    "    )\n",
    "print(cebra_time_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Out of a total 142 stimulus presentations:\n",
      "           35 left spots\n",
      "           35 right spots\n",
      "Full neural dataset shape is: (43350, 93122)\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'start' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[26], line 28\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[39m# truncate neural\u001b[39;00m\n\u001b[1;32m     22\u001b[0m \u001b[39m# select first TIMESTEPS timesteps and random ROIS rois\u001b[39;00m\n\u001b[1;32m     23\u001b[0m neural_indexes \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39msort(\n\u001b[1;32m     24\u001b[0m                     np\u001b[39m.\u001b[39mrandom\u001b[39m.\u001b[39mchoice(\n\u001b[1;32m     25\u001b[0m                                 np\u001b[39m.\u001b[39marange(neural\u001b[39m.\u001b[39mshape[\u001b[39m1\u001b[39m]), size\u001b[39m=\u001b[39mROIS, replace\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m\n\u001b[1;32m     26\u001b[0m                                 )\n\u001b[1;32m     27\u001b[0m                     )\n\u001b[0;32m---> 28\u001b[0m neural \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marray(neural[start:stop, neural_indexes])\n\u001b[1;32m     29\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mTruncated neural dataset shape is: \u001b[39m\u001b[39m{\u001b[39;00mneural\u001b[39m.\u001b[39mshape\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m)\n\u001b[1;32m     31\u001b[0m \u001b[39m# assert shapes\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'start' is not defined"
     ]
    }
   ],
   "source": [
    "# to place in load data loop\n",
    "\n",
    "filepath = FILEPATH\n",
    "with h5py.File(filepath, 'r') as f:\n",
    "\n",
    "    # get stimulus presentations\n",
    "    stimuli = f['visuomotor']['presentations']\n",
    "    stim_type = stimuli['stim_type']\n",
    "    spot_pres_fr_l = np.where(np.isin(stim_type, 1))[0]\n",
    "    spot_pres_fr_r = np.where(np.isin(stim_type, 2))[0]\n",
    "    print(f'Out of a total {stim_type.size} stimulus presentations:\\n \\\n",
    "          {spot_pres_fr_l.size} left spots\\n \\\n",
    "          {spot_pres_fr_r.size} right spots')\n",
    "    \n",
    "    spot_pres_fr = np.column_stack((spot_pres_fr_l, spot_pres_fr_r))\n",
    "\n",
    "    # neural\n",
    "    neural = f['rois']['dfof']\n",
    "    print(f\"Full neural dataset shape is: {neural.shape}\")\n",
    "\n",
    "    # truncate neural\n",
    "    # select first TIMESTEPS timesteps and random ROIS rois\n",
    "    neural_indexes = np.sort(\n",
    "                        np.random.choice(\n",
    "                                    np.arange(neural.shape[1]), size=ROIS, replace=False\n",
    "                                    )\n",
    "                        )\n",
    "    neural = np.array(neural[start:stop, neural_indexes])\n",
    "    print(f'Truncated neural dataset shape is: {neural.shape}')\n",
    "\n",
    "    # assert shapes\n",
    "    assert(neural.shape == (TIMESTEPS, ROIS))\n",
    "    assert(spot_pres_fr == (spot_pres_fr_l.size, 2))\n",
    "    \n",
    "    np.savez(f'{data_folder}{filepath_spot_pres_fr}', spot_pres_fr=spot_pres_fr)\n",
    "    np.savez(f'{data_folder}{neural}', neural=neural)\n",
    "\n",
    "\n",
    "\n",
    "print(spot_pres_fr_l)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5, 0, 0, 5])"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = [1,1,1,1]\n",
    "b = [4,1,1,4]\n",
    "np.bitwise_xor(a,b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = np.zeros((100000,)).astype(int)\n",
    "a[[stim_pres_fr_l.astype(int), stim_end_fr_l.astype(int)]] = 1\n",
    "a = np.bitwise_xor.accumulate(a) | a\n",
    "a[793:825]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  798.,  1963.,  2933.,  4218.,  5638.,  6683.,  8263.,  9583.,\n",
       "       10928., 12078., 13513., 14858., 15888., 17053., 17988., 18998.,\n",
       "       20083., 21278., 22388., 23538., 24703., 25863., 27303., 28623.,\n",
       "       29693., 30903., 32078., 33643., 34828., 36173., 37023., 38368.,\n",
       "       39488., 40788., 42343.])"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stim_pres_fr_l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 1])"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = np.array([1,1,1,1])\n",
    "b = np.array([4,1,1,4])\n",
    "np.bitwise_xor.accumulate(a)|a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([  0,   4,   7,  11,  16,  20,  25,  29,  34,  38,  43,  48,  51,\n",
       "         55,  58,  61,  65,  69,  72,  76,  80,  83,  88,  93,  96, 100,\n",
       "        104, 109, 113, 117, 120, 125, 129, 133, 138])]"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stim_pres_idx_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = FILEPATH\n",
    "stim_types = STIM_TYPES\n",
    "neural = np.zeros((100000,1))\n",
    "with h5py.File(filepath, 'r') as f:\n",
    "\n",
    "    # get stimulus presentations\n",
    "    stimuli = f['visuomotor']['presentations']\n",
    "    stim_type = stimuli['stim_type'].astype(int)\n",
    "    stim_on_fr = stimuli['onset_frame'].astype(int)\n",
    "    stim_end_fr = stimuli['offset_frame'].astype(int)\n",
    "\n",
    "\n",
    "    (stim_pres_idx_list, stim_on_fr_list,\n",
    "     stim_end_fr_list, stim_on_mask_list, stim_dur_list)  = [],[],[],[],[]\n",
    "\n",
    "    for stim in STIMS:\n",
    "\n",
    "        # convert stim name to stim number\n",
    "        stim_num = STIM_TYPES[stim]\n",
    "\n",
    "        # find the presentation indexes for all specified stim types\n",
    "        stim_pres_idx_list.append(np.where(np.isin(stim_type, stim_num))[0])\n",
    "\n",
    "        # index stim onset frames with the presentation indexes\n",
    "        this_stim_on_frame = stim_on_fr[stim_pres_idx_list[stim_num]]\n",
    "        stim_on_fr_list.append(this_stim_on_frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stim_on_mask_list[1][793:825]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = FILEPATH\n",
    "stim_types = STIM_TYPES\n",
    "neural = np.zeros((100000,1))\n",
    "with h5py.File(filepath, 'r') as f:\n",
    "\n",
    "    # get stimulus presentations\n",
    "    stimuli = f['visuomotor']['presentations']\n",
    "    stim_type = stimuli['stim_type'].astype(int)\n",
    "    stim_on_fr = stimuli['onset_frame'].astype(int)\n",
    "    stim_end_fr = stimuli['offset_frame'].astype(int)\n",
    "\n",
    "\n",
    "    (stim_pres_idx_list, stim_on_fr_list,\n",
    "     stim_end_fr_list, stim_on_mask_list, stim_dur_list)  = [],[],[],[],[]\n",
    "\n",
    "    for stim in STIMS:\n",
    "\n",
    "        # convert stim name to stim number\n",
    "        stim_num = STIM_TYPES[stim]  \n",
    "\n",
    "        # find the presentation indexes for all specified stim types\n",
    "        # must account for data index starting at 1\n",
    "        stim_pres_idx_list.append(np.where(np.isin(stim_type, stim_num + 1))[0])\n",
    "\n",
    "        # index stim onset frames with the presentation indexes\n",
    "        this_stim_on_frame = stim_on_fr[stim_pres_idx_list[stim_num]]\n",
    "        stim_on_fr_list.append(this_stim_on_frame)\n",
    "\n",
    "        # index stim end frames with the presentation indexes\n",
    "        this_stim_end_frame = stim_end_fr[stim_pres_idx_list[stim_num]]\n",
    "        stim_end_fr_list.append(this_stim_end_frame)\n",
    "\n",
    "        # create a boolean mask of stimulus presentation frames (1 == stimulus on, 0 == stimulus off)\n",
    "        stim_on_mask = np.zeros(neural.shape[0]).astype(int)\n",
    "        stim_on_mask[[stim_on_fr_list[stim_num], stim_end_fr_list[stim_num]]] = 1\n",
    "        stim_on_mask = np.bitwise_xor.accumulate(stim_on_mask) | stim_on_mask\n",
    "        stim_on_mask_list.append(stim_on_mask)\n",
    "\n",
    "        # find duration (in frames) of each presentation of the stimulus\n",
    "        # recording rate is 5 Hz\n",
    "        stim_dur_list.append(this_stim_end_frame - this_stim_on_frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full neural dataset shape is: (43350, 93122)\n"
     ]
    }
   ],
   "source": [
    "# load data for a single fish\n",
    "# TODO - put this in context of LOAD if-else statement\n",
    "\n",
    "##  params ##\n",
    "\n",
    "# variables\n",
    "stim_types = STIM_TYPES\n",
    "\n",
    "# paths\n",
    "filepath = FILEPATH\n",
    "filename = filepath.split('/')[-1][:-3] # fish and date only\n",
    "data_folder = 'data/'\n",
    "filename_spot_pres_fr = f'{filename[-9:]}_spot_pres_fr.npz'\n",
    "filename_dfof = f'{filename[-9:]}_dfof_stim_decode.npz'\n",
    "\n",
    "\n",
    "with h5py.File(filepath, 'r') as f:\n",
    "\n",
    "    ## neural ##\n",
    "\n",
    "    neural = f['rois']['dfof']\n",
    "    print(f\"Full neural dataset shape is: {neural.shape}\")\n",
    "\n",
    "    # get stimulus presentations\n",
    "    stimuli = f['visuomotor']['presentations']\n",
    "    stim_type = stimuli['stim_type'].astype(int)\n",
    "    stim_on_fr = stimuli['onset_frame'].astype(int)\n",
    "    stim_end_fr = stimuli['offset_frame'].astype(int)\n",
    "\n",
    "    # initialise lists for the chosen stimuli\n",
    "    (stim_pres_idx_list, stim_on_fr_list,\n",
    "     stim_end_fr_list, stim_on_mask_list, stim_dur_list)  = [],[],[],[],[]\n",
    "\n",
    "    ## stimuli ##\n",
    "\n",
    "    # loop through chosen stimuli and find boolean masks for their 'on' frames\n",
    "    for stim in STIMS:\n",
    "\n",
    "        # convert stim name to stim number\n",
    "        stim_num = STIM_TYPES[stim]  \n",
    "\n",
    "        # find the presentation indexes for all specified stim types\n",
    "        # must account for data index starting at 1\n",
    "        stim_pres_idx_list.append(np.where(np.isin(stim_type, stim_num + 1))[0])\n",
    "\n",
    "        # index stim onset frames with the presentation indexes\n",
    "        this_stim_on_frame = stim_on_fr[stim_pres_idx_list[stim_num]]\n",
    "        stim_on_fr_list.append(this_stim_on_frame)\n",
    "\n",
    "        # index stim end frames with the presentation indexes\n",
    "        this_stim_end_frame = stim_end_fr[stim_pres_idx_list[stim_num]]\n",
    "        stim_end_fr_list.append(this_stim_end_frame)\n",
    "\n",
    "        # create a boolean mask of stimulus presentation frames (1 == stimulus on, 0 == stimulus off)\n",
    "        stim_on_mask = np.zeros(neural.shape[0]).astype(int)\n",
    "        stim_on_mask[[stim_on_fr_list[stim_num], stim_end_fr_list[stim_num]]] = 1\n",
    "        stim_on_mask = np.bitwise_xor.accumulate(stim_on_mask) | stim_on_mask\n",
    "        stim_on_mask_list.append(stim_on_mask)\n",
    "\n",
    "        # find duration (in frames) of each presentation of the stimulus\n",
    "        # recording rate is 5 Hz\n",
    "        stim_dur_list.append(this_stim_end_frame - this_stim_on_frame)\n",
    "\n",
    "        # assert shapes\n",
    "        assert(stim_on_mask_list[0].size == neural.shape[0])\n",
    "\n",
    "        # save data\n",
    "        # TODO - save neural and save stim data into separate columns of the same dataset\n",
    "\n",
    "        # load data\n",
    "        # TODO - write this    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accessing data...\n",
      "Out of a total 142 stimulus presentations:\n",
      "             35 left spots\n",
      "             35 right spots\n",
      "Full neural dataset shape is: (43350, 93122)\n",
      "Truncated neural dataset shape is: (15000, 10000)\n",
      "f1_221027_spot_pres_fr.npz_left loaded.\n",
      "f1_221027_dfof_stim_decode.npz loaded.\n",
      "[  0   4   7  11  16  20  25  29  34  38  43  48  51  55  58  61  65  69\n",
      "  72  76  80  83  88  93  96 100 104 109 113 117 120 125 129 133 138]\n"
     ]
    }
   ],
   "source": [
    "# # load data (single fish)\n",
    "\n",
    "# paths\n",
    "filepath = FILEPATH\n",
    "filename = filepath.split('/')[-1][:-3] # fish and date only\n",
    "data_folder = 'data/'\n",
    "filename_spot_pres_fr = f'{filename[-9:]}_spot_pres_fr.npz'\n",
    "filename_dfof = f'{filename[-9:]}_dfof_stim_decode.npz'\n",
    "\n",
    "# choose where in dataset to sample\n",
    "start, stop = 0, 0+TIMESTEPS\n",
    "\n",
    "# extract eye position and neural data\n",
    "# do not attempt to load the entire file \n",
    "print(\"Accessing data...\")\n",
    "\n",
    "# load data if it is already saved, and LOAD == True\n",
    "if LOAD == True:\n",
    "    try:\n",
    "        spot_pres_fr = cebra.load_data(f'{data_folder}{filename_spot_pres_fr}', key=\"spot_pres_fr\")\n",
    "        print(f\"{filename_spot_pres_fr}_left loaded.\")\n",
    "        spot_pres_fr = cebra.load_data(f'{data_folder}{filename_spot_pres_fr}', key=\"spot_pres_fr\")\n",
    "        print(f\"{filename_spot_pres_fr}_right loaded.\")\n",
    "        neural = cebra.load_data(f'{data_folder}{filename_dfof}', key=\"neural\")\n",
    "        print(f\"{filename_dfof} loaded.\")\n",
    "    \n",
    "    except:\n",
    "        pass\n",
    "        print(\"Couldn't load data into CEBRA\")\n",
    "\n",
    "else:\n",
    "    with h5py.File(filepath, 'r') as f:\n",
    "\n",
    "        # neural\n",
    "        neural = f['rois']['dfof']\n",
    "        print(f\"Full neural dataset shape is: {neural.shape}\")\n",
    "\n",
    "        \n",
    "        # get stimulus presentations\n",
    "        stimuli = f['visuomotor']['presentations']\n",
    "        stim_type = stimuli['stim_type'].astype(int)\n",
    "\n",
    "        for stim in STIMS:\n",
    "            \n",
    "\n",
    "\n",
    "        # find the presentation indexes with left or right spots\n",
    "        stim_pres_idx_l = np.where(np.isin(stim_type, 1))[0]    # left spots\n",
    "        stim_pres_idx_r = np.where(np.isin(stim_type, 2))[0]    # right spots\n",
    "\n",
    "        # print spot information\n",
    "        print(f'Out of a total {stim_type.size} stimulus presentations:\\n \\\n",
    "        {spot_pres_fr_l.size} left spots\\n \\\n",
    "        {spot_pres_fr_r.size} right spots')\n",
    "\n",
    "        # index stim onset frames with the presentation indexes\n",
    "        stim_onset_fr = stimuli['onset_frame'].astype(int)\n",
    "        stim_pres_fr_l = stim_onset_fr[stim_pres_idx_l]\n",
    "        stim_pres_fr_r = stim_onset_fr[stim_pres_idx_r]\n",
    "\n",
    "        # index stim end frames with the presentation indexes\n",
    "        stim_end_fr = stimuli['offset_frame'].astype(int)\n",
    "        stim_end_fr_l = stim_end_fr[stim_pres_idx_l]\n",
    "        stim_end_fr_r = stim_end_fr[stim_pres_idx_r]\n",
    "\n",
    "        # create masks of stim onset/stim end\n",
    "        # left spot\n",
    "        stim_on_l = np.zeros(neural.shape[0])\n",
    "        stim_on_l[[stim_pres_fr_l, stim_end_fr_l]] = 1\n",
    "        np.bitwise_xor.accumulate(stim_on_l) | stim_on_l\n",
    "        # right spot\n",
    "        stim_on_r = np.zeros(neural.shape[0])\n",
    "        stim_on_r[[stim_pres_fr_r, stim_end_fr_r]] = 1\n",
    "        np.bitwise_xor.accumulate(stim_on_r) | stim_on_r\n",
    "\n",
    "        # find duration (in frames) of each presentation\n",
    "        # (neural recording is at 5Hz)\n",
    "        stim_dur_l = stim_end_fr_l - stim_pres_fr_l\n",
    "        stim_dur_r = stim_end_fr_r - stim_pres_fr_r\n",
    "        \n",
    "        spot_pres_fr = np.column_stack((spot_pres_fr_l, spot_pres_fr_r))\n",
    "\n",
    "        # assert shapes\n",
    "        assert(neural.shape == (TIMESTEPS, ROIS))\n",
    "        assert(spot_pres_fr.shape == (spot_pres_fr_l.size, 2))\n",
    "\n",
    "        # save data\n",
    "        np.savez(f'{data_folder}{filename_spot_pres_fr}', spot_pres_fr=spot_pres_fr)\n",
    "        np.savez(f'{data_folder}{filename_dfof}', neural=neural)\n",
    "\n",
    "        # load data\n",
    "        spot_pres_fr = cebra.load_data(f'{data_folder}{filename_spot_pres_fr}', key=\"spot_pres_fr\")\n",
    "        print(f\"{filename_spot_pres_fr}_left loaded.\")\n",
    "        neural = cebra.load_data(f'{data_folder}{filename_dfof}', key=\"neural\")\n",
    "        print(f\"{filename_dfof} loaded.\")\n",
    "    \n",
    "\n",
    "print(spot_pres_fr_l)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # fit model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 2)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# remember to create an array containing both variables\n",
    "post_left_spot = np.arange(3)\n",
    "post_right_spot = np.arange(3)\n",
    "post_spot = np.column_stack([post_left_spot, post_right_spot])\n",
    "post_spot.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cebra",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
