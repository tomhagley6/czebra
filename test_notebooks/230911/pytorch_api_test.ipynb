{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Will require loading in the neural dataset to run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = cebra.distributions.base.HasGenerator('cuda', 0)\n",
    "a.generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = cebra.distributions.discrete.Discrete(discrete, device='cpu', seed='none')\n",
    "uniform_sample = b.sample_uniform(20)\n",
    "uniform_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sort(discrete[uniform_sample])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = cebra.distributions.discrete.DiscreteUniform(discrete, device='cpu', seed='none')\n",
    "uniform_sample_2 = c.sample_prior(20)\n",
    "sample_conditional_2 = c.sample_conditional(discrete[uniform_sample_2])\n",
    "uniform_sample_2, values_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sort(discrete[uniform_sample_2]), np.sort(discrete[sample_conditional_2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### load and preprocess data for a single fish ###\n",
    "# if LOAD == True, load pre-saved .npz file data. Otherwise,\n",
    "# create this data as specified below and save it to .npz\n",
    "\n",
    "##  params ##\n",
    "\n",
    "# variables\n",
    "stim_types = STIM_TYPES     # dict of all possible stims\n",
    "stims = STIMS               # stim types chosen for analysis\n",
    "timesteps = TIMESTEPS\n",
    "rois = ROIS\n",
    "stim_length_frames = STIM_LENGTH_FRAMES # used for selecting the second half of stimuli\n",
    "\n",
    "start, stop = 0, timesteps\n",
    "load_data = LOAD_DATA\n",
    "save_data = SAVE_DATA\n",
    "\n",
    "# paths\n",
    "filepath = FILEPATH\n",
    "filename = filepath.split('/')[-1][:-3] # fish and date only\n",
    "data_folder = DATA_PATH\n",
    "data_folder_HDD = '/media/storage/DATA/tom/'\n",
    "filename_stim_pres_frames = f'{filename[-9:]}_stim_pres_frames.npz'\n",
    "filename_neural_subset = f'{filename[-9:]}_{SIGNAL_TYPE}_subset.npz'\n",
    "filename_neural_indexes = f'{filename[-9:]}_neural_indexes_all.npz'\n",
    "\n",
    "# specify loading anatomically unrestricted data or tectal-restricted data\n",
    "if RESTRICT_TO_TECTAL:\n",
    "    filename_neural_subset = f'{filename[-9:]}_{SIGNAL_TYPE}_subset_tectal.npz'\n",
    "    filename_neural_indexes = f'{filename[-9:]}_neural_indexes_tectal.npz'\n",
    "\n",
    "# if not loading data, but not wanting to overwrite saved data, save as a temp file\n",
    "if not save_data and not load_data: \n",
    "    print(f\"Producing temp files...\")\n",
    "    filename_neural = f'{filename[-9:]}_{SIGNAL_TYPE}_TEMPORARY_DELETE.npz'\n",
    "    filename_neural_subset = f'{filename[-9:]}_{SIGNAL_TYPE}_subset_TEMPORARY_DELETE.npz'\n",
    "    filename_stim_pres_frames = f'{filename[-9:]}_stim_pres_frames_TEMPORARY_DELETE.npz'\n",
    "\n",
    "\n",
    "print(\"Accessing data...\")\n",
    "\n",
    "## load data ##\n",
    "if load_data:\n",
    "        \n",
    "    # Attempt to load neural data from .npz, otherwise load from HDD .h5\n",
    "    # Load small datasets from .npz files\n",
    "    print(\"Loading data...\")\n",
    "    (neural, stim_on_frames) =  load_data_from_file(filepath, data_folder, filename_neural_subset,\n",
    "                                                    filename_stim_pres_frames)\n",
    "\n",
    "\n",
    "## else generate data ##\n",
    "else:\n",
    "    with h5py.File(filepath, 'r') as f:\n",
    "\n",
    "            ## neural ##\n",
    "\n",
    "            neural_dataset = f['rois'][f'{SIGNAL_TYPE}']\n",
    "            print(f\"Full neural dataset shape is: {neural_dataset.shape}\")\n",
    "\n",
    "            neural, neural_indexes = generate_neural_dataset(f, neural_dataset, rois, timesteps=timesteps)\n",
    "\n",
    "            ## stimuli ##\n",
    "\n",
    "            (stim_pres_idx_list, \n",
    "             stim_on_fr_list,\n",
    "             stim_on_fr_list_half,\n",
    "             stim_end_fr_list, \n",
    "             stim_on_mask_list, \n",
    "             stim_on_mask_list_half,\n",
    "             stim_dur_list) = create_stimulus_presentation_masks(f, neural, stims, stim_types,\n",
    "                                                                stim_length_frames, timesteps)\n",
    "\n",
    "            # if set, create a separate continuous \"contrast \"variable for each stimulus, to train\n",
    "            # the CEBRA model on alongside the discrete variable\n",
    "            cont_left_spot = np.zeros(neural.shape[0])\n",
    "            cont_right_spot = np.zeros(neural.shape[0])\n",
    "            cont_stimuli = [cont_left_spot, cont_right_spot]\n",
    "            for i in range(len(cont_stimuli)):\n",
    "                this_stim_on_fr = stim_on_fr_list[i]\n",
    "                for pres in this_stim_on_fr:\n",
    "                    cont_stimuli[i][pres:pres+STIM_LENGTH_FRAMES] = np.arange(STIM_LENGTH_FRAMES)\n",
    "\n",
    "\n",
    "\n",
    "            ## save data ##\n",
    "            print(\"Saving data...\")\n",
    "\n",
    "            # choose which stim_on_mask to use (half or full)\n",
    "            if HALF_STIM_MASK:\n",
    "                stim_on_mask_dataset = np.column_stack(stim_on_mask_list_half[:])\n",
    "            else: \n",
    "                 stim_on_mask_dataset = np.column_stack(stim_on_mask_list[:])\n",
    "\n",
    "            assert(stim_on_mask_dataset.shape == (neural.shape[0], len(stims)))\n",
    "            if timesteps:\n",
    "                assert(neural.shape == (timesteps, rois))\n",
    "\n",
    "            save_data_to_file(stim_on_mask_dataset, neural, neural_indexes, \n",
    "              data_folder, filename_stim_pres_frames, filename_neural_subset,\n",
    "              filename_neural_indexes)\n",
    "\n",
    "            ## load data ##\n",
    "            # Attempt to load neural data from .npz, otherwise load from HDD .h5\n",
    "            # Load small datasets from .npz files\n",
    "            print(\"Loading data...\")\n",
    "            \n",
    "            (neural, stim_on_frames) = load_data_from_file(filepath, data_folder, filename_neural_subset,\n",
    "                                                           filename_stim_pres_frames)\n",
    "\n",
    "# end else\n",
    "\n",
    "## final processing ##\n",
    "\n",
    "# format the discrete variable\n",
    "# left spot == 1, right spot == 2, no stimulus == 0 \n",
    "left_spot, right_spot = stim_on_frames[:,0], stim_on_frames[:,1]\n",
    "right_spot = np.multiply(right_spot, 2)\n",
    "discrete = np.add(left_spot, right_spot)\n",
    "\n",
    "# separate data into training and test\n",
    "training_test_split = TRAINING_TEST_SPLIT\n",
    "split_idx = int(np.round(neural.shape[0] * training_test_split))\n",
    "neural_train, neural_test = neural[:split_idx, :], neural[split_idx:, :]\n",
    "discrete_train, discrete_test = discrete[:split_idx], discrete[split_idx:]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "czebra",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
